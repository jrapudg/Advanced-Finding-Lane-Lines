{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "## The goals / steps of this project are the following:\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./writeup_images/image_1_chess_distorsion.png \"Distorsion Correction Chessborad\"\n",
    "[image2]: ./writeup_images/image_2_distorsion_straight_lines.png \"Distorsion Correction\"\n",
    "[image3]: ./writeup_images/image_3_warped.png \"Warped Image\"\n",
    "\n",
    "[image4]: ./writeup_images/image_4_color_1.png\n",
    "[image5]: ./writeup_images/image_5_color.png\n",
    "[image6]: ./writeup_images/image_6_color.png\n",
    "\n",
    "[image7]: ./writeup_images/image_7_thresh.png\n",
    "[image8]: ./writeup_images/image_8_thresh.png\n",
    "[image9]: ./writeup_images/image_9_thresh.png\n",
    "[image10]: ./writeup_images/image_10_thresh.png\n",
    "[image11]: ./writeup_images/image_11_thresh.png\n",
    "[image12]: ./writeup_images/image_12_thresh.png\n",
    "[image13]: ./writeup_images/image_13_thresh.png\n",
    "[image14]: ./writeup_images/image_14_thresh.png\n",
    "[image15]: ./writeup_images/image_15_thresh.png\n",
    "[image16]: ./writeup_images/image_16_thresh.png\n",
    "[image17]: ./writeup_images/image_17_thresh.png\n",
    "[image18]: ./writeup_images/image_18_thresh.png\n",
    "[image19]: ./writeup_images/image_19_thresh.png\n",
    "[image20]: ./writeup_images/image_20_thresh.png\n",
    "[image21]: ./writeup_images/image_window_final_1.png\n",
    "[image22]: ./writeup_images/image_window_final_2.png\n",
    "[image23]: ./writeup_images/image_window_final_3.png\n",
    "[image24]: ./writeup_images/final_1.png\n",
    "[image25]: ./writeup_images/final_2.png\n",
    "[image26]: ./writeup_images/final_3.png\n",
    "[image27]: ./writeup_images/final_4.png\n",
    "[image28]: ./writeup_images/final_5.png\n",
    "[image29]: ./writeup_images/final_6.png\n",
    "\n",
    "[video1]: ./project_video_FINAL.mp4 \"Video1\"\n",
    "[video2]: ./challenge_video_output_FINAL.mp4 \"Video2\"\n",
    "\n",
    "\n",
    "### Camera Calibration\n",
    "\n",
    "#### 1. Briefly state how you computed the camera matrix and distortion coefficients. Provide an example of a distortion corrected calibration image.\n",
    "\n",
    "The code for this step is as follows:\n",
    "```python\n",
    "def camera_calibration(img, objpoints, imgpoints):\n",
    "    original = img.copy()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "        #cv2.imwrite('origin'+str(i+1)+'.jpg',original)\n",
    "        #cv2.imwrite('corners_detected'+str(i+1)+'.jpg',img)\n",
    "        ax1.imshow(original)\n",
    "        ax1.set_title('Original Image '+str(i+1), fontsize=30)\n",
    "        ax2.imshow(img)\n",
    "        ax2.set_title('Corners detected '+str(i+1),fontsize=30)\n",
    " \n",
    "    return objpoints, imgpoints\n",
    "\n",
    "def cal_matrix(imge, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, imge.shape[:-1],None,None)\n",
    "    \n",
    "    return mtx, dist\n",
    "\n",
    "def undistort(img,mtx,dist):\n",
    "    undist = cv2.undistort(img,mtx,dist,None,mtx)\n",
    "    return undist\n",
    "\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "#Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for i, fname in enumerate(images):\n",
    "    img = mpimg.imread(fname)\n",
    "    objpoints, imgpoints = camera_calibration(img, objpoints, imgpoints)\n",
    "\n",
    "    \n",
    "dst = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "frame = mpimg.imread('test_images/test4.jpg')\n",
    "\n",
    "mtx, dist = cal_matrix(dst, objpoints, imgpoints)\n",
    "\n",
    "#Chessboard image Undistortion\n",
    "udst = undistort(dst, mtx,dist)\n",
    "#Frame of the Video Undistortion\n",
    "undistorted = undistort(frame, mtx,dist)\n",
    "\n",
    "```\n",
    "\n",
    "I start by preparing \"object points\", which will be the (x, y, z) coordinates of the chessboard corners in the world. Here I am assuming the chessboard is fixed on the (x, y) plane at z=0, such that the object points are the same for each calibration image.  Thus, `objp` is just a replicated array of coordinates, and `objpoints` will be appended with a copy of it every time I successfully detect all chessboard corners in a test image.  `imgpoints` will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection. This is donde using the `camera_calibration(img, objpoints, imgpoints)` function.\n",
    "\n",
    "I then used the output `objpoints` and `imgpoints` to compute the camera calibration (mtx) and distortion coefficients (dst) using the `cal_matrix(imge, objpoints, imgpoints)` function. I applied this distortion correction to the test image of the chessboard using the `undistort(img,mtx,dist)` function and obtained this result: \n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "\n",
    "### Pipeline (single images)\n",
    "\n",
    "#### 1. Provide an example of a distortion-corrected image.\n",
    "\n",
    "To demonstrate this step, I will describe how I apply the distortion correction to one of the test images. As it was descreibed above, once the mtx and dst matrices are calculated, the distrosion correction of the previous image is made using the `undistort(img,mtx,dist)` function and obtained this result: \n",
    "![alt text][image2]\n",
    "\n",
    "\n",
    "#### 2. Describe how (and identify where in your code) you used color transforms, gradients or other methods to create a thresholded binary image.  Provide an example of a binary image result.\n",
    "\n",
    "I used a combination of color and gradient thresholds to generate a binary image as follows:\n",
    "```python\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(50,100)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if (orient=='x'):\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    elif (orient == 'y'):\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    # Apply threshold\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)[:,:,2]\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    return dir_binary\n",
    "\n",
    "def img_thresh(img, s_sobel_thresh=(8, 100), sx_thresh=(10, 100)):\n",
    "    img = np.copy(img)\n",
    "    ksize = 3\n",
    "    # Apply each of the thresholding functions\n",
    "    # Sobel x\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(50, 150))\n",
    "    # Sobel y\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(50, 150))\n",
    "    # Magnitud\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    # Dir\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "    combined_grad = np.zeros_like(dir_binary)\n",
    "    combined_grad[((gradx == 1)  & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "    #def color_thresh_combined(img, s_thresh, l_thresh, v_thresh, b_thresh):\n",
    "    v_thresh = [230,255]\n",
    "    s_thresh = [235,255]\n",
    "    l_thresh = [215,255]\n",
    "    b_thresh = [230,255]\n",
    "    lab_b_thresh = [195,255]\n",
    "    \n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    V_binary = hsv[:,:,2]\n",
    "    V_binary = V_binary*(255/np.max(V_binary))\n",
    "    V_thresh_binary= np.zeros_like(V_binary)\n",
    "    V_thresh_binary[(V_binary >= v_thresh[0]) & (V_binary <= v_thresh[1])] = 1\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S_binary = hls[:,:,2]\n",
    "    max_sat = np.max(S_binary)\n",
    "    if max_sat >= 245:\n",
    "        S_binary = S_binary*(210/np.max(S_binary))\n",
    "    # Threshold x gradient\n",
    "    S_thresh_binary= np.zeros_like(S_binary)\n",
    "    S_thresh_binary[(S_binary >= s_thresh[0]) & (S_binary <= s_thresh[1])] = 1\n",
    "\n",
    "\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    L_binary = luv[:,:,0]\n",
    "    max_l = np.max(L_binary)\n",
    "    L_binary = L_binary*(255/np.max(L_binary))\n",
    "    # Threshold x gradient\n",
    "    L_thresh_binary= np.zeros_like(L_binary)\n",
    "    L_thresh_binary[(L_binary >= l_thresh[0]) & (L_binary <= l_thresh[1])] = 1\n",
    "\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    LAB_B_binary = lab[:,:,2]\n",
    "    max_value = np.max(LAB_B_binary)\n",
    "    if ((max_value <= 190)&((max_l < 252)|(max_sat < 220))):\n",
    "        if (max_value <= 170):\n",
    "            LAB_B_binary = LAB_B_binary*(210/np.max(LAB_B_binary))\n",
    "        else:\n",
    "            LAB_B_binary = LAB_B_binary*(255/np.max(LAB_B_binary)) \n",
    "    lab_B_thresh_binary= np.zeros_like(LAB_B_binary)\n",
    "    lab_B_thresh_binary[(LAB_B_binary >= lab_b_thresh[0]) & (LAB_B_binary <= lab_b_thresh[1])] = 1\n",
    "    \n",
    "    \n",
    "    B_binary = img[:,:,0]\n",
    "    max_blue = np.max(B_binary)\n",
    "    #print(max_blue)\n",
    "    # Threshold x gradient\n",
    "    if max_blue <= 238:\n",
    "        B_binary= B_binary*(255/np.max(B_binary))\n",
    "    B_thresh_binary = np.zeros_like(B_binary)\n",
    "    B_thresh_binary[(B_binary >= b_thresh[0]) & (B_binary <= b_thresh[1])] = 1\n",
    "\n",
    "    color_binary= np.zeros_like(B_binary)\n",
    "    color_binary[((V_thresh_binary == 1) | (S_thresh_binary == 1) | (L_thresh_binary == 1) | (B_thresh_binary == 1))] = 1\n",
    "    \n",
    "   # Sobel x\n",
    "    sobelx = cv2.Sobel(L_binary, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(S_binary)\n",
    "    sobel = cv2.Sobel(S_binary , cv2.CV_64F, 1, 0)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel_s = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    s_binary[(scaled_sobel_s >= s_sobel_thresh[0]) & (scaled_sobel_s <= s_sobel_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    #color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    combined = np.zeros_like(sxbinary)\n",
    "    combined[((color_binary == 1)|(lab_B_thresh_binary == 1)|((s_binary == 1) & (sxbinary == 1)))] = 1\n",
    "    \n",
    "    return combined\n",
    "```\n",
    "\n",
    "Regarding color transforms, I use and filter the Value Channel of the HSV color space with a threshold of v_thresh = [230,255], the Saturation Channel of the HLS color space with a threshold of s_thresh = [235,255], the Light Channel of the LUV color space with a threshold of l_thresh = [215,255] and the Blue Channel of the RGB color space with a threshold of b_thresh = [230,255].\n",
    "    \n",
    "Here are some examples of my output for this step.\n",
    "\n",
    "### Image 1\n",
    "![alt text][image4]\n",
    "### Image 2\n",
    "![alt text][image5]\n",
    "### Image 3\n",
    "![alt text][image6]\n",
    "\n",
    "As it can be seen, it works ok for image 1 and 2. However, when the image is dark or shadowed as in Image 3 (from the challenge video), the color spaces thresholds are not enough to find the lanes. Therefore, I use the gradient of the Saturation Channel and the Light Channel with a threshold of s_sobel_thresh = (8, 100) and sx_thresh = (10, 100), respectively.\n",
    "    \n",
    "The color `Yellow` of the lines is something we can also take advantage of. In the LAB color space, positive values of B Channel respresent the color yellow. Thus, the B Channel of the LAB color space with a threshold of lab_b_thresh = [195,255] is used.\n",
    "\n",
    "Here are some examples of my output for this step.\n",
    "\n",
    "### Image 4\n",
    "![alt text][image7]\n",
    "### Image 5\n",
    "![alt text][image8]\n",
    "### Image 6\n",
    "![alt text][image9]\n",
    "### Image 7\n",
    "![alt text][image10]\n",
    "### Image 8\n",
    "![alt text][image11]\n",
    "### Image 9\n",
    "![alt text][image12]\n",
    "### Image 10\n",
    "![alt text][image13]\n",
    "### Image 11\n",
    "![alt text][image14]\n",
    "### Image 12\n",
    "![alt text][image15]\n",
    "### Image 13\n",
    "![alt text][image16]\n",
    "### Image 14\n",
    "![alt text][image17]\n",
    "### Image 15\n",
    "![alt text][image18]\n",
    "### Image 16\n",
    "![alt text][image19]\n",
    "### Image 17\n",
    "![alt text][image20]\n",
    "\n",
    "\n",
    "From these images, one can observed that `Light Sobel Threshold` and `Saturation Sobel Threshold` images are really noisy. However, if they are added with an logic `and` operator, as in  `Light & Saturation Thresholds` image, I can easly identify lines in shadowed and dark images.\n",
    "The `Combined Thresholds` image shows the combiantion of all color sapces, B_channel of the LAB color space and the Light and Saturation Sobel binary images with an `or` operator.\n",
    "\n",
    "#### 3. Describe how (and identify where in your code) you performed a perspective transform and provide an example of a transformed image.\n",
    "\n",
    "The code for my perspective transform includes a function called `perspective_transform(img, offset = 320)`, which appears as follows:\n",
    "```python\n",
    "\n",
    "def perspective_transform(img, offset = 320):\n",
    "    #define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "    #Note: you could pick any four of the detected corners \n",
    "    # as long as those four corners define a rectangle\n",
    "    #One especially smart way to do this would be to use four well-chosen\n",
    "    # corners that were automatically detected during the undistortion steps\n",
    "    #We recommend using the automatic detection of corners in your cod\n",
    "    src = np.float32([(0.451*img.shape[1], 0.6388*img.shape[0]), (0.1585*img.shape[1], img.shape[0]), (0.88*img.shape[1], img.shape[0]), (0.55*img.shape[1], 0.6388*img.shape[0])])\n",
    "            # For destination points, I'm arbitrarily choosing some points to be\n",
    "            # a nice fit for displaying our warped result \n",
    "            # again, not exact, but close enough for our purposes\n",
    "    dst = np.float32([(offset, 0), (offset, img.shape[0]), (img.shape[1]-offset, img.shape[0]), (img.shape[1]-offset, 0)]) # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    inv_M = cv2.getPerspectiveTransform(dst,src)\n",
    "                # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img,M,(img.shape[1], img.shape[0]),flags=cv2.INTER_LINEAR)\n",
    "    return warped, inv_M\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    " The function takes as inputs an image (`img`), as well as the offset to define the destination points (`dst`). Inside the functions is defined the source (`src`) points.  I chose the hardcode the source and destination points in the following manner:\n",
    "```python\n",
    "offset= 250\n",
    "src = np.float32([(0.451*img.shape[1], 0.6388*img.shape[0]),\n",
    "                  (0.1585*img.shape[1], img.shape[0]), \n",
    "                  (0.88*img.shape[1], img.shape[0]), \n",
    "                  (0.55*img.shape[1], 0.6388*img.shape[0])])\n",
    "            # For destination points, I'm arbitrarily choosing some points to be\n",
    "            # a nice fit for displaying our warped result \n",
    "            # again, not exact, but close enough for our purposes\n",
    "dst = np.float32([(offset, 0), \n",
    "                  (offset, img.shape[0]), \n",
    "                  (img.shape[1]-offset, img.shape[0]), \n",
    "                  (img.shape[1]-offset, 0)]) \n",
    "            # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "```\n",
    "\n",
    "This resulted in the following source and destination points:\n",
    "\n",
    "| Source        | Destination   | \n",
    "|:-------------:|:-------------:| \n",
    "| 585, 460      | 320, 0        | \n",
    "| 203, 720      | 320, 720      |\n",
    "| 1127, 720     | 960, 720      |\n",
    "| 695, 460      | 960, 0        |\n",
    "\n",
    "I verified that my perspective transform was working as expected by showing the test image and its warped counterpart to verify that the lines appear parallel in the warped image.\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "#### 4. Describe how (and identify where in your code) you identified lane-line pixels and fit their positions with a polynomial?\n",
    "\n",
    "The indentification of the lane-line pixels is done by two functions. First, the `find_lane_pixels(binary_warped)` function which code is:\n",
    "```python\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 30\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        \n",
    "        win_xleft_low = leftx_current - margin   # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        \n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "    \n",
    "    left_fit, right_fit = (None, None)\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    if len(leftx) != 0:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "    return left_fit, right_fit, leftx, lefty, rightx, righty, out_img\n",
    "```\n",
    "It takes as input the binary_warped image and performs a histogram filter to find the x coordinates of the peaks where there are more pixels. Then, from the bottom to the top of the image, a search is performed through sliding windows. The numeber of windows is preset and the starting points are the x coordinates previously found in the histogram step. During this search, each time that pixels are found, the windows is re-center for the next step. Finnally, I fit my lane lines with a 2nd order polynomial kinda with thw `cv2.polyfit(x,y,grade)` like this:\n",
    "\n",
    "### Image 1 Window_Search\n",
    "\n",
    "![all_text][image21]\n",
    "\n",
    "### Image 2 Window_Search\n",
    "![all_text][image22]\n",
    "\n",
    "The second function is used with prior information. Once you have found a polynomial for the lane-lines, it is not necesary to do a blind search. The `search_around_poly(binary_warped, left_fit_search, right_fit_search)` function search around a region defined by the previous polynomial fit and a margin. Its code is:\n",
    "\n",
    "```python\n",
    "def search_around_poly(binary_warped, left_fit_search, right_fit_search):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!  \n",
    "    margin = 80\n",
    "\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit_search[0]*(nonzeroy**2) + left_fit_search[1]*nonzeroy + \n",
    "                    left_fit_search[2] - margin)) & (nonzerox < (left_fit_search[0]*(nonzeroy**2) + \n",
    "                    left_fit_search[1]*nonzeroy + left_fit_search[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit_search[0]*(nonzeroy**2) + right_fit_search[1]*nonzeroy + \n",
    "                    right_fit_search[2] - margin)) & (nonzerox < (right_fit_search[0]*(nonzeroy**2) + \n",
    "                    right_fit_search[1]*nonzeroy + right_fit_search[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fit_new, right_fit_new = (None, None)\n",
    "    if len(leftx) != 0:\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit_new = np.polyfit(lefty, leftx, 2)\n",
    "    if len(rightx) != 0:\n",
    "        right_fit_new = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    \n",
    "    if left_fit_new is not None:\n",
    "        left_fitx = left_fit_new[0]*ploty**2 + left_fit_new[1]*ploty + left_fit_new[2]\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        \n",
    "    if right_fit_new is not None:\n",
    "        right_fitx = right_fit_new[0]*ploty**2 + right_fit_new[1]*ploty + right_fit_new[2]\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    \n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    \n",
    "    return left_fit_new, right_fit_new, leftx, lefty, rightx, righty, result\n",
    "```\n",
    "![alt text][image23]\n",
    "\n",
    "#### 5. Describe how (and identify where in your code) you calculated the radius of curvature of the lane and the position of the vehicle with respect to center.\n",
    "\n",
    "I did this in lines # through # in my code in `my_other_file.py`\n",
    "\n",
    "#### 6. Provide an example image of your result plotted back down onto the road such that the lane area is identified clearly.\n",
    "\n",
    "I implemented this step in lines as follows:\n",
    "\n",
    "```python\n",
    "def draw_lines(img, inv_M, left_fit, right_fit):\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    margin = 50\n",
    "    out_img = np.zeros_like(img).astype(np.uint8)\n",
    "    left_line_window0 = np.array([np.flipud(np.transpose(np.vstack([left_fitx-margin, ploty])))]) \n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))]) \n",
    "    right_line_window3 = np.array([np.transpose(np.vstack([right_fitx+margin, ploty]))])                          \n",
    "    \n",
    "    central_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    \n",
    "    left_side_pts = np.hstack((left_line_window1,left_line_window0))\n",
    "    right_side_pts = np.hstack((left_line_window2, right_line_window3))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(out_img, np.int_([left_side_pts]), (255,255,0))\n",
    "    cv2.fillPoly(out_img, np.int_([right_side_pts]), (255,255, 0))\n",
    "    cv2.fillPoly(out_img, np.int_([central_line_pts]), (0,255, 0))\n",
    "    warped_image = cv2.warpPerspective(out_img,inv_M,(out_img.shape[1], out_img.shape[0]),flags=cv2.INTER_LINEAR)\n",
    "    result = cv2.addWeighted(img, 1, warped_image , 0.3, 0)\n",
    "    \n",
    "    # Plot the polynomial lines onto the image\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    return result\n",
    "\n",
    "def draw_info(img,left_curverad, right_curverad, center_difference, side_position):\n",
    "    # Display radius of curvature and vehicle offset\n",
    "    cv2.putText(img, 'Coded by Juan ALVAREZ', (10, 50), cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                            (255, 63, 150), 4)\n",
    "    # Display radius of curvature and vehicle offset\n",
    "    cv2.putText(img, 'Radius of Curvature of Left line is ' + str(round(left_curverad/1000, 3)) + '(Km)', (10, 100), cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                            (255, 63, 150), 4)\n",
    "    cv2.putText(img, 'Radius of Curvature of Right line is ' + str(round(right_curverad/1000, 3)) + '(Km)', (10, 150), cv2.FONT_HERSHEY_PLAIN, 2,\n",
    "                            (255, 63, 150), 4)\n",
    "    cv2.putText(img, 'Vehicle is ' + str(abs(round(center_difference, 3))) + 'm ' + side_position + ' of center', (10, 200), cv2.FONT_HERSHEY_PLAIN, \n",
    "                            2, (255, 63, 150), 4) \n",
    "    return img\n",
    "```\n",
    "I use two functions. The `draw_lines(img, inv_M, left_fit, right_fit)` and `draw_info(img,left_curverad, right_curverad, center_difference, side_position)` functions. \n",
    "\n",
    "The fist one perfomrs the inverse perspective transform with the matrix inv_M and plot the lines and the region between lines on the original image. The second one draws the information of my name, the radius of curvature and the position of the car with respect of the center of the camera and the found lines.\n",
    "\n",
    "Here is an example of my result on a test image:\n",
    "\n",
    "![alt text][image25]\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline (video)\n",
    "\n",
    "#### 1. Provide a link to your final video output.  Your pipeline should perform reasonably well on the entire project video (wobbly lines are ok but no catastrophic failures that would cause the car to drive off the road!).\n",
    "\n",
    "Here's a [link to my video result of the project video](./project_video_FINAL.mp4)\n",
    "\n",
    "Here's a [link to my video result of the challenge video](./challenge_video_output_FINAL.mp4)\n",
    "\n",
    "---\n",
    "\n",
    "### Discussion\n",
    "\n",
    "#### 1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?\n",
    "\n",
    "Here I'll talk about the approach I took, what techniques I used, what worked and why, where the pipeline might fail and how I might improve it if I were going to pursue this project further.  \n",
    "\n",
    "First, through thresholding color spaces and gradients of the image and combining them, the lines were found. This approach presented problems when the frame was darker and blurrier. Dark shadows represent a huge challenge for my approach. Furthermore, when a car is approaching to the line, it affects the line detections and modifies the fiiting. I also made a line class to keep track the lines during the video, calculate some attributes and methods of the line and perform a sanity check before drawing a new line. The sanity check consist in checking if the lines detected:\n",
    "\n",
    "* are parallels\n",
    "* have a similar curvature with respect to the last line detected\n",
    "* Have a similar horizontal distance to the car\n",
    "\n",
    "I save the fit values of the lines of the last 5 detections. If a line is not detected, the first of the 5 records is deleted.\n",
    "\n",
    "The code for the line class is:\n",
    "\n",
    "```python\n",
    "class Line():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #plot y\n",
    "        self.ploty = None\n",
    "        #coordiantes of base position\n",
    "        self.base_xy = None\n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        self.reset = False\n",
    "    \n",
    "    def calculate_radius_of_curvature(self):\n",
    "        if self.best_fit is not None and self.ploty is not None:\n",
    "            ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "            xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "\n",
    "            # Define y-value where we want radius of curvature\n",
    "            # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "            y_eval = np.max(self.ploty)\n",
    "\n",
    "            if self.allx is not None:\n",
    "                # Fit new polynomials to x,y in world space\n",
    "                fit_world = np.polyfit(self.ploty*ym_per_pix, self.bestx*xm_per_pix, 2)\n",
    "\n",
    "                # Calculate the new radii of curvature\n",
    "                ##### TO-DO: Implement the calculation of R_curve (radius of curvature) #####\n",
    "                radius = (1+(2*fit_world[0]*y_eval+fit_world[1])**2)**(3/2)/(np.absolute(2*fit_world[0]))\n",
    "        return radius\n",
    "    \n",
    "    def update_radius_of_curvature(radius):\n",
    "        self.radius_of_curvature = radius\n",
    "        \n",
    "    def calculate_line_base_pos(self, center):\n",
    "        self.line_base_pos = self.base_xy[0] - center\n",
    "    \n",
    "    def update_base_xy(self):\n",
    "        y_val = np.max(self.ploty)\n",
    "        x_val = self.best_fit[0]*y_val**2 + self.best_fit[1]*y_val + self.best_fit[2]\n",
    "        self.base_xy = (x_val, y_val)\n",
    "            \n",
    "    def update_line_fit(self, line_fit, x_coordinates, y_coordinates):\n",
    "        # add a found fit to the line, up to n\n",
    "        if line_fit is not None:\n",
    "                \n",
    "            if self.best_fit is not None:\n",
    "                # if we have a best fit, see how this new fit compares\n",
    "                self.diffs = abs(line_fit-self.best_fit)\n",
    "                if (self.diffs[0] > 0.001 or \\\n",
    "                   self.diffs[1] > 1 or \\\n",
    "                   self.diffs[2] > 100) and \\\n",
    "                   len(self.current_fit) > 0:\n",
    "                    # bad fit! abort! abort! ... well, unless there are no fits in the current_fit queue, then we'll take it\n",
    "                    self.detected = False\n",
    "                else:\n",
    "                    self.detected = True\n",
    "                    \n",
    "                    self.allx = x_coordinates\n",
    "                    self.ally = y_coordinates\n",
    "                    \n",
    "                    fitx = line_fit[0]*self.ploty**2 + line_fit[1]*self.ploty + line_fit[2]\n",
    "                    \n",
    "                    self.recent_xfitted.append(fitx)\n",
    "                    self.current_fit.append(line_fit)\n",
    "                    \n",
    "                    if len(self.current_fit) > 5:\n",
    "                        # throw out old fits, keep newest n\n",
    "                        self.current_fit = self.current_fit[len(self.current_fit)-5:]\n",
    "                        self.recent_xfitted = self.recent_xfitted[len(self.recent_xfitted)-5:]\n",
    "                    \n",
    "                    self.best_fit = np.average(self.current_fit, axis=0)\n",
    "                    radius = self.calculate_radius_of_curvature()\n",
    "                    self.radius_of_curvature = radius\n",
    "                    self.update_base_xy()\n",
    "                    \n",
    "                    self.bestx = np.average(self.recent_xfitted, axis=0)\n",
    "            else:\n",
    "                self.detected = True\n",
    "                \n",
    "                self.current_fit = [line_fit]\n",
    "                \n",
    "                self.allx = x_coordinates\n",
    "                self.ally = y_coordinates\n",
    "                fitx = line_fit[0]*self.ploty**2 + line_fit[1]*self.ploty + line_fit[2]\n",
    "                self.recent_xfitted = [fitx]\n",
    "        \n",
    "                self.bestx = fitx\n",
    "            \n",
    "                self.best_fit = line_fit\n",
    "                radius = self.calculate_radius_of_curvature()\n",
    "                self.radius_of_curvature = radius\n",
    "                self.update_base_xy()\n",
    "            \n",
    "        # or remove one from the history, if not found\n",
    "        else:\n",
    "            self.detected = False\n",
    "           \n",
    "            if len(self.current_fit) > 1:\n",
    "                # delete last line_fit\n",
    "                self.current_fit = self.current_fit[:len(self.current_fit)-1]\n",
    "                self.best_fit = np.average(self.current_fit, axis=0)\n",
    "                self.recent_xfitted = self.recent_xfitted[:len(self.recent_xfitted)-1]\n",
    "                self.bestx = np.average(self.recent_xfitted, axis=0)\n",
    "\n",
    "```\n",
    "The sanity check is done by this code:\n",
    "\n",
    "```python\n",
    "#SANITY CHECK\n",
    "if left_fit is not None and right_fit is not None:\n",
    "    # calculate x-intercept (bottom of image, x=image_height) for fits\n",
    "    \n",
    "    left_fit_bottom = left_fit[0]*height**2 + left_fit[1]*height + left_fit[2]\n",
    "    right_fit_bottom = right_fit[0]*height**2 + right_fit[1]*height + right_fit[2]\n",
    "    interception_bottom_difference = abs(right_fit_bottom-left_fit_bottom)\n",
    "\n",
    "    left_fit_middle = left_fit[0]*(height/6)**2 + left_fit[1]*(height/6) + left_fit[2]\n",
    "    right_fit_middle = right_fit[0]*(height/6)**2 + right_fit[1]*(height/6) + right_fit[2]\n",
    "    interception_middle_difference = abs(right_fit_middle-left_fit_middle)\n",
    "\n",
    "    if (abs(0.43*width - interception_bottom_difference) > 0.15*width) or (abs(0.42*width - interception_middle_difference) > 0.2*width):\n",
    "        left_fit = None\n",
    "        right_fit = None\n",
    "\n",
    "    else:\n",
    "        if (Left.radius_of_curvature is not None) and (abs(measure_radius_of_curvature(leftx, lefty) - Left.radius_of_curvature) > 3*Left.radius_of_curvature):\n",
    "            left_fit = None\n",
    "        if (Right.radius_of_curvature is not None) and (abs(measure_radius_of_curvature(rightx, righty) - Right.radius_of_curvature) > 3*Right.radius_of_curvature):\n",
    "            right_fit = None \n",
    "\n",
    "```\n",
    "\n",
    "This helped too much to accurately decide if drawing a line or not. A better detection of the lines with more robust methods will help a lot. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
